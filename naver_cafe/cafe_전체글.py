import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time
from auth import get_credentials
from googleapiclient.discovery import build
from datetime import datetime

# êµ¬ê¸€ ì‹œíŠ¸ ID
SPREADSHEET_ID = '1Yve6JJzgJaD4KXe2a8vB53zaWOUGsubcG_1t7XeNVmQ'

def get_cafe_urls_from_sheet():
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì¹´í˜ URL ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸°"""
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)

    result = service.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range='ì¹´í˜_ë¦¬ìŠ¤íŠ¸!C2:C' # Cì—´ì—ì„œ URL ê°€ì ¸ì˜¤ê¸° (í—¤ë” ì œì™¸)
    ).execute()
    values = result.get('values', [])
    if not values:
        print('ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ì¹´í˜ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return []
    else:
        return [row[0] for row in values if row and row[0]]

def update_cafe_data(row_index, member_count, recent_articles_count, hotdeal_boards):
    """êµ¬ê¸€ ì‹œíŠ¸ì— ì¹´í˜ ë°ì´í„° ì—…ë°ì´íŠ¸"""
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)
    
    # ì‹¤ì œ ì‹œíŠ¸ì˜ í–‰ ë²ˆí˜¸ (í—¤ë” ì œì™¸)
    sheet_row = row_index + 2 # í—¤ë”ê°€ 1í–‰ì´ë¯€ë¡œ +2
    
    # ë©¤ë²„ìˆ˜ ì—…ë°ì´íŠ¸ (Dì—´)
    if member_count:
        service.spreadsheets().values().update(
            spreadsheetId=SPREADSHEET_ID,
            range=f'ì¹´í˜_ë¦¬ìŠ¤íŠ¸!D{sheet_row}',
            valueInputOption='RAW',
            body={'values': [[member_count]]}
        ).execute()
    
    # 30ë¶„ ê²Œì‹œê¸€ ìˆ˜ ì—…ë°ì´íŠ¸ (Eì—´)
    service.spreadsheets().values().update(
        spreadsheetId=SPREADSHEET_ID,
        range=f'ì¹´í˜_ë¦¬ìŠ¤íŠ¸!E{sheet_row}',
        valueInputOption='RAW',
        body={'values': [[recent_articles_count]]}
    ).execute()
    
    # í•«ë”œ ê²Œì‹œíŒ ì—…ë°ì´íŠ¸ (Kì—´)
    if hotdeal_boards:
        hotdeal_text = ', '.join(hotdeal_boards)
        service.spreadsheets().values().update(
            spreadsheetId=SPREADSHEET_ID,
            range=f'ì¹´í˜_ë¦¬ìŠ¤íŠ¸!K{sheet_row}',
            valueInputOption='RAW',
            body={'values': [[hotdeal_text]]}
        ).execute()
    
    print(f"í–‰ {sheet_row} ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")

def scrape_cafe_data(url, cafe_index):
    """ê°œë³„ ì¹´í˜ ë°ì´í„° ìŠ¤í¬ë˜í•‘"""
    print(f"\n{'='*60}")
    print(f"ì¹´í˜ {cafe_index + 1} ì²˜ë¦¬ ì¤‘: {url}")
    print(f"{'='*80}")

    options = Options()
    options.add_experimental_option("detach", True)
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--log-level=3')
    options.add_argument('--silent')
    options.add_experimental_option('excludeSwitches', ['enable-logging'])
    options.add_experimental_option('useAutomationExtension', False)

    driver = webdriver.Chrome(options=options)

    try:
        # 1. URLì„ í†µí•´ ì¹´í˜ë¥¼ ì—°ë‹¤
        driver.get(url)
        time.sleep(2)  # í˜ì´ì§€ ë¡œë”©ì„ ìœ„í•œ ëŒ€ê¸° ì‹œê°„
        print("1. ì¹´í˜ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")

        # í˜„ì¬ í˜ì´ì§€ URL í™•ì¸
        print(f"í˜„ì¬ í˜ì´ì§€ URL: {driver.current_url}")

        # í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥
        try:
            page_source = driver.page_source
            with open("cafe_page_source.txt", "w", encoding="utf-8") as f:
                f.write(page_source)
            print("í˜ì´ì§€ ì†ŒìŠ¤ê°€ 'cafe_page_source.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        # ë©”ì¸ í”„ë ˆì„ìœ¼ë¡œ ëŒì•„ê°€ê¸° (iframe ì „í™˜ ì „ì—)
        driver.switch_to.default_content()

        # ì¹´í˜ ë©¤ë²„ìˆ˜ ì •ë³´ ì¶œë ¥ - ë©”ì¸ í˜ì´ì§€ì—ì„œ ì°¾ê¸°
        print("ì¹´í˜ ë©¤ë²„ìˆ˜ ì¶”ì¶œ ì‹œë„...")
        member_count = None
        try:
            # ë°©ë²• 0: ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡°ì— ë§ëŠ” ì„ íƒì (ìµœìš°ì„ )
            member_count_element = driver.find_element(By.CSS_SELECTOR, "li.mem-cnt-info em")
            member_count = member_count_element.text.split('ë¹„ê³µê°œ')[0].strip()
            print(f"ì¹´í˜ ë©¤ë²„ìˆ˜: {member_count}")
        except Exception as e:
            print(f"ë°©ë²• 0 ì‹¤íŒ¨: {e}")
            try:
                # ë°©ë²• 1: em íƒœê·¸ì—ì„œ ìˆ«ìë§Œ ì°¾ê¸°
                em_elements = driver.find_elements(By.TAG_NAME, "em")
                for em in em_elements:
                    text = em.text.strip()
                    if ',' in text and 'ë¹„ê³µê°œ' in text:
                        member_count = text.split('ë¹„ê³µê°œ')[0].strip()
                        print(f"ì¹´í˜ ë©¤ë²„ìˆ˜: {member_count}")
                        break
            except Exception as e:
                print(f"ë°©ë²• 1 ì‹¤íŒ¨: {e}")
                try:
                    # ë°©ë²• 2: XPathë¡œ mem-cnt-info ì°¾ê¸°
                    member_count_element = driver.find_element(By.XPATH, "//li[@class='mem-cnt-info']//em")
                    member_count = member_count_element.text.split('ë¹„ê³µê°œ')[0].strip()
                    print(f"ì¹´í˜ ë©¤ë²„ìˆ˜: {member_count}")
                except Exception as e:
                    print(f"ë°©ë²• 2 ì‹¤íŒ¨: {e}")
                    try:
                        # ë°©ë²• 3: í…ìŠ¤íŠ¸ë¡œ ì§ì ‘ ì°¾ê¸°
                        page_source = driver.page_source
                        import re
                        match = re.search(r'<em>([0-9,]+)<span class="ico_lock2">ë¹„ê³µê°œ</span></em>', page_source)
                        if match:
                            member_count = match.group(1)
                            print(f"ì¹´í˜ ë©¤ë²„ìˆ˜: {member_count}")
                        else:
                            print("ë©¤ë²„ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        print(f"ë°©ë²• 3 ì‹¤íŒ¨: {e}")
                        print("ë©¤ë²„ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì¹´í˜ ë©”ì¸ í˜ì´ì§€ë¡œ ì§ì ‘ ì´ë™ (ê²Œì‹œíŒ ëª©ë¡ì´ ìˆëŠ” í˜ì´ì§€)
        print("ì¹´í˜ ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
        driver.get(url)
        time.sleep(3)

        # iframeìœ¼ë¡œ ì „í™˜
        print("iframeìœ¼ë¡œ ì „í™˜ ì¤‘...")
        try:
            WebDriverWait(driver, 10).until(
                EC.frame_to_be_available_and_switch_to_it((By.ID, "cafe_main"))
            )
            print("iframe ì „í™˜ ì„±ê³µ")
            time.sleep(2)  # iframe ë‚´ë¶€ ë¡œë”© ëŒ€ê¸° ì¶”ê°€

            # iframe ë‚´ë¶€ í˜ì´ì§€ ì†ŒìŠ¤ë„ ì €ì¥
            try:
                iframe_page_source = driver.page_source
                with open("cafe_iframe_source.txt", "w", encoding="utf-8") as f:
                    f.write(iframe_page_source)
                print("iframe ë‚´ë¶€ í˜ì´ì§€ ì†ŒìŠ¤ê°€ 'cafe_iframe_source.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"iframe ë‚´ë¶€ í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"iframe ì „í™˜ ì‹¤íŒ¨: {e}")
            driver.switch_to.default_content()

        # 2. ê²Œì‹œíŒ ì´ë¦„ë“¤ ì¶œë ¥
        print("2. ê²Œì‹œíŒ ì´ë¦„ë“¤ ì¶œë ¥")

        # ë©”ì¸ í”„ë ˆì„ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        driver.switch_to.default_content()

        try:
            # ì‹¤ì œ ì¹´í˜ ë©”ë‰´ êµ¬ì¡°ì— ë§ëŠ” ì„ íƒì ì‚¬ìš©
            board_links = []
            
            # ë°©ë²• 1: cafe-menu-list ë‚´ì˜ ëª¨ë“  ë§í¬ ì°¾ê¸°
            try:
                links1 = driver.find_elements(By.CSS_SELECTOR, ".cafe-menu-list a.gm-tcol-c")
                board_links.extend(links1)
                print(f"ë°©ë²• 1ë¡œ {len(links1)}ê°œ ì°¾ìŒ")
            except Exception as e:
                print(f"ë°©ë²• 1 ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 2: íŠ¹ë³„ ë©”ë‰´ ë§í¬ ì°¾ê¸°
            try:
                links2 = driver.find_elements(By.CSS_SELECTOR, ".special-menu a.link_special")
                board_links.extend(links2)
                print(f"ë°©ë²• 2ë¡œ {len(links2)}ê°œ ì°¾ìŒ")
            except Exception as e:
                print(f"ë°©ë²• 2 ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 3: ëª¨ë“  menuLink IDë¥¼ ê°€ì§„ ë§í¬ ì°¾ê¸°
            try:
                links3 = driver.find_elements(By.CSS_SELECTOR, "a[id^='menuLink']")
                board_links.extend(links3)
                print(f"ë°©ë²• 3ìœ¼ë¡œ {len(links3)}ê°œ ì°¾ìŒ")
            except Exception as e:
                print(f"ë°©ë²• 3 ì‹¤íŒ¨: {e}")
            
            # ì¤‘ë³µ ì œê±° ë° í•œê¸€ í¬í•¨ ê²Œì‹œíŒë§Œ í•„í„°ë§
            unique_links = []
            seen_hrefs = set()
            for link in board_links:
                try:
                    href = link.get_attribute('href')
                    text = link.text.strip()
                    
                    # í•œê¸€ì´ í¬í•¨ë˜ê³  '%'ê°€ ì—†ëŠ” ê²Œì‹œíŒë§Œ í•„í„°ë§
                    if href and text and href not in seen_hrefs:
                        # í•œê¸€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        has_korean = any('\u3131' <= char <= '\u318E' or '\uAC00' <= char <= '\uD7A3' for char in text)
                        # '%' ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        has_percent = '%' in text
                        
                        if has_korean and not has_percent:
                            unique_links.append((text, href, link))
                            seen_hrefs.add(href)
                            print(f"í•œê¸€ ê²Œì‹œíŒ ì¶”ê°€: {text}")
                            
                except Exception as e:
                    print(f"ë§í¬ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    continue
            
            print(f"ì´ {len(unique_links)}ê°œì˜ ê²Œì‹œíŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
            
            def is_recent_post(time_text):
                """ì‘ì„± ì‹œê°„ì´ 30ë¶„ ì´ë‚´ì¸ì§€ í™•ì¸"""
                import re
                from datetime import datetime, timedelta
                
                # í˜„ì¬ ì‹œê°„
                now = datetime.now()
                
                # ì‹œê°„ íŒ¨í„´ ë§¤ì¹­
                if 'ë¶„' in time_text:
                    minutes = int(re.search(r'(\d+)ë¶„', time_text).group(1))
                    return minutes <= 30
                elif 'ì‹œê°„' in time_text:
                    hours = int(re.search(r'(\d+)ì‹œê°„', time_text).group(1))
                    return hours == 0  # 0ì‹œê°„ = 30ë¶„ ì´ë‚´
                elif 'ì¼' in time_text or 'ì›”' in time_text or 'ë…„' in time_text:
                    return False  # 1ì¼ ì´ìƒì€ ì œì™¸
                elif ':' in time_text:  # ì‹œ:ë¶„ í˜•ì‹ (ì˜ˆ: 18:24)
                    try:
                        # ì‹œ:ë¶„ í˜•ì‹ íŒŒì‹±
                        time_parts = time_text.split(':')
                        if len(time_parts) == 2:
                            hour = int(time_parts[0])
                            minute = int(time_parts[1])
                            
                            # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì‹œê°„ ê°ì²´ ìƒì„±
                            post_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
                            
                            # í˜„ì¬ ì‹œê°„ê³¼ì˜ ì°¨ì´ ê³„ì‚°
                            time_diff = now - post_time
                            
                            # 30ë¶„ ì´ë‚´ì¸ì§€ í™•ì¸
                            return time_diff.total_seconds() <= 30 * 60
                        else:
                            return False
                    except:
                        return False
                else:
                    return False  # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ì€ ì œì™¸

            def scrape_recent_articles(driver, board_name):
                """í˜„ì¬ ê²Œì‹œíŒì—ì„œ ìµœê·¼ 30ë¶„ ì´ë‚´ ê¸€ë“¤ì„ ìŠ¤í¬ë˜í•‘"""
                try:
                    # ìƒˆë¡œìš´ ë„¤ì´ë²„ ì¹´í˜ êµ¬ì¡°ëŠ” iframeì´ ì—†ìœ¼ë¯€ë¡œ ì „í™˜í•˜ì§€ ì•ŠìŒ
                    time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    
                    total_recent_count = 0
                    current_page = 1
                    max_page = 10  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ ê²€ìƒ‰
                    
                    print(f"\n=== {board_name} ê²Œì‹œíŒ ìµœê·¼ ê¸€ë“¤ ===")
                    
                    while current_page <= max_page:
                        print(f"\n--- {current_page}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘ ---")
                        
                        # ê²Œì‹œê¸€ ëª©ë¡ ì°¾ê¸° (ìƒˆë¡œìš´ ë„¤ì´ë²„ ì¹´í˜ êµ¬ì¡°)
                        try:
                            # ë°©ë²• 1: article-board ë‚´ì˜ tr ì°¾ê¸°
                            articles = driver.find_elements(By.CSS_SELECTOR, ".article-board tr")
                            print(f"ë°©ë²• 1ë¡œ {len(articles)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        except:
                            try:
                                # ë°©ë²• 2: article í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ë§í¬ê°€ ìˆëŠ” tr ì°¾ê¸°
                                articles = driver.find_elements(By.CSS_SELECTOR, "tr:has(.article)")
                                print(f"ë°©ë²• 2ë¡œ {len(articles)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            except:
                                # ë°©ë²• 3: ëª¨ë“  trì—ì„œ article ë§í¬ ì°¾ê¸°
                                all_trs = driver.find_elements(By.TAG_NAME, "tr")
                                articles = []
                                for tr in all_trs:
                                    try:
                                        tr.find_element(By.CSS_SELECTOR, ".article")
                                        articles.append(tr)
                                    except:
                                        continue
                                print(f"ë°©ë²• 3ìœ¼ë¡œ {len(articles)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        
                        page_recent_count = 0
                        old_articles_found = 0  # 30ë¶„ ì´ìƒ ëœ ê¸€ ê°œìˆ˜
                        
                        for article in articles:
                            try:
                                # ê³µì§€/í•„ë… ê²Œì‹œê¸€ ì œì™¸
                                try:
                                    notice_element = article.find_element(By.CSS_SELECTOR, "span.inner")
                                    notice_text = notice_element.text.strip()
                                    if notice_text in ["ê³µì§€", "í•„ë…"]:
                                        continue
                                except:
                                    pass  # ê³µì§€/í•„ë… íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ê²Œì‹œê¸€
                                
                                # ì‘ì„± ì‹œê°„ í™•ì¸ (ìƒˆë¡œìš´ êµ¬ì¡°)
                                try:
                                    time_element = article.find_element(By.CSS_SELECTOR, "td:nth-child(4)")
                                    time_text = time_element.text.strip()
                                except:
                                    try:
                                        # ë‹¤ë¥¸ ì‹œê°„ ì„ íƒì ì‹œë„
                                        time_elements = article.find_elements(By.TAG_NAME, "td")
                                        if len(time_elements) >= 4:
                                            time_text = time_elements[3].text.strip()
                                        else:
                                            time_text = "ì•Œ ìˆ˜ ì—†ìŒ"
                                    except:
                                        time_text = "ì•Œ ìˆ˜ ì—†ìŒ"
                                
                                # 30ë¶„ ì´ë‚´ ê¸€ì¸ì§€ í™•ì¸
                                if is_recent_post(time_text):
                                    # ê²Œì‹œê¸€ ì •ë³´ ì¶”ì¶œ (ìƒˆë¡œìš´ êµ¬ì¡°)
                                    title_element = article.find_element(By.CSS_SELECTOR, ".article")
                                    title = title_element.text.strip()
                                    url = title_element.get_attribute("href")
                                    
                                    # ëŒ“ê¸€ ìˆ˜ (ìƒˆë¡œìš´ êµ¬ì¡°)
                                    try:
                                        comment_element = article.find_element(By.CSS_SELECTOR, ".cmt")
                                        comment_text = comment_element.text.strip()
                                        # [ìˆ«ì] í˜•íƒœì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                                        import re
                                        comment_match = re.search(r'\[(\d+)\]', comment_text)
                                        comment_count = comment_match.group(1) if comment_match else "0"
                                    except:
                                        comment_count = "0"
                                    
                                    # ë‹‰ë„¤ì„ (ìƒˆë¡œìš´ êµ¬ì¡°)
                                    try:
                                        nickname_element = article.find_element(By.CSS_SELECTOR, ".nickname")
                                        nickname = nickname_element.text.strip()
                                    except:
                                        nickname = "ì•Œ ìˆ˜ ì—†ìŒ"
                                    
                                    # ì¡°íšŒìˆ˜ (ìƒˆë¡œìš´ êµ¬ì¡°)
                                    try:
                                        view_element = article.find_element(By.CSS_SELECTOR, ".type_readCount")
                                        view_count = view_element.text.strip()
                                    except:
                                        try:
                                            # ë‹¤ë¥¸ ì¡°íšŒìˆ˜ ì„ íƒì ì‹œë„
                                            view_elements = article.find_elements(By.TAG_NAME, "td")
                                            for td in view_elements:
                                                if "type_readCount" in td.get_attribute("class") or "":
                                                    view_count = td.text.strip()
                                                    break
                                            else:
                                                view_count = "ì•Œ ìˆ˜ ì—†ìŒ"
                                        except:
                                            view_count = "ì•Œ ìˆ˜ ì—†ìŒ"
                                    
                                    # ê²°ê³¼ ì¶œë ¥
                                    print(f"\nì œëª©: {title}")
                                    print(f"URL: {url}")
                                    print(f"ëŒ“ê¸€ ìˆ˜: {comment_count}")
                                    print(f"ë‹‰ë„¤ì„: {nickname}")
                                    print(f"ì‘ì„±ì‹œê°: {time_text}")
                                    print(f"ì¡°íšŒìˆ˜: {view_count}")
                                    print("-" * 50)
                                    
                                    page_recent_count += 1
                                    total_recent_count += 1
                                else:
                                    old_articles_found += 1
                            except Exception as e:
                                print(f"ê²Œì‹œê¸€ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                                continue
                        
                        print(f"{current_page}í˜ì´ì§€ì—ì„œ {page_recent_count}ê°œì˜ ìµœê·¼ ê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        
                        # 30ë¶„ ì´ìƒ ëœ ê¸€ì´ ë§ì´ ë‚˜ì˜¤ë©´ ë” ì´ìƒ ê²€ìƒ‰í•  í•„ìš” ì—†ìŒ
                        if old_articles_found > 5:  # 5ê°œ ì´ìƒì˜ ì˜¤ë˜ëœ ê¸€ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                            print(f"30ë¶„ ì´ìƒ ëœ ê¸€ì´ ë§ì´ ë‚˜ì™€ì„œ {current_page}í˜ì´ì§€ì—ì„œ ê²€ìƒ‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                            break
                        
                        # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                        try:
                            # ìƒˆë¡œìš´ ë„¤ì´ë²„ ì¹´í˜ êµ¬ì¡°ì˜ í˜ì´ì§€ë„¤ì´ì…˜ (button ê¸°ë°˜)
                            page_buttons = driver.find_elements(By.CSS_SELECTOR, "button.btn.number")
                            
                            # ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
                            next_page_number = current_page + 1
                            next_page_button = None
                            
                            # í˜„ì¬ í‘œì‹œëœ í˜ì´ì§€ ë²”ìœ„ í™•ì¸ (1-10, 11-20 ë“±)
                            current_range_start = ((current_page - 1) // 10) * 10 + 1
                            current_range_end = current_range_start + 9
                            # ë‹¤ìŒ í˜ì´ì§€ê°€ í˜„ì¬ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                            if next_page_number <= current_range_end:
                                # í˜„ì¬ ë²”ìœ„ ë‚´ì—ì„œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸°
                                for button in page_buttons:
                                    button_text = button.text.strip()
                                    if button_text == str(next_page_number):
                                        next_page_button = button
                                        break
                            else:
                                # ë‹¤ìŒ ë²”ìœ„ë¡œ ë„˜ì–´ê°€ì•¼ í•¨ - "ë‹¤ìŒ" ë²„íŠ¼ í´ë¦­
                                try:
                                    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn.type_next")
                                    next_button.click()
                                    time.sleep(2)
                                    current_page += 1
                                    print(f"{current_page}í˜ì´ì§€ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤ (ë‹¤ìŒ ë²”ìœ„).")
                                    continue
                                except:
                                    print(f"ë‹¤ìŒ ë²”ìœ„ë¡œ ì´ë™í•  ìˆ˜ ì—†ì–´ì„œ {current_page}í˜ì´ì§€ì—ì„œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                                    break
                            
                            if next_page_button:
                                next_page_button.click()
                                time.sleep(2)
                                current_page += 1
                                print(f"{current_page}í˜ì´ì§€ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
                            else:
                                print(f"{next_page_number}í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ {current_page}í˜ì´ì§€ì—ì„œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                                break
                                
                        except Exception as e:
                            print(f"ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ì–´ì„œ {current_page}í˜ì´ì§€ì—ì„œ ì¢…ë£Œí•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                            break
                    
                    if total_recent_count == 0:
                        print(f"{board_name} ê²Œì‹œíŒì— ìµœê·¼ 30ë¶„ ì´ë‚´ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print(f"{board_name} ê²Œì‹œíŒì—ì„œ ì´ {total_recent_count}ê°œì˜ ìµœê·¼ ê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    
                except Exception as e:
                    print(f"{board_name} ê²Œì‹œíŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                    # ë””ë²„ê¹…ì„ ìœ„í•´ í˜ì´ì§€ ì†ŒìŠ¤ ì¼ë¶€ ì¶œë ¥
                    try:
                        print("í˜ì´ì§€ ì†ŒìŠ¤ ì¼ë¶€:", driver.page_source[:1000])
                    except:
                        print("í˜ì´ì§€ ì†ŒìŠ¤ í™•ì¸ ì‹¤íŒ¨")
                
                return total_recent_count
            
            # 3. 'ì „ì²´ê¸€ë³´ê¸°' ê²Œì‹œíŒë§Œ ì°¾ì•„ì„œ í¬ë¡¤ë§
            print("\n3. 'ì „ì²´ê¸€ë³´ê¸°' ê²Œì‹œíŒ ì°¾ê¸° ë° í¬ë¡¤ë§ ì‹œì‘")
            
            # 'ì „ì²´ê¸€ë³´ê¸°' ê²Œì‹œíŒ ì°¾ê¸°
            whole_board = None
            for board_name, href, link_element in unique_links:
                if 'ì „ì²´ê¸€ë³´ê¸°' in board_name:
                    whole_board = (board_name, href, link_element)
                    break
            
            if whole_board:
                board_name, href, link_element = whole_board
                print(f"'ì „ì²´ê¸€ë³´ê¸°' ê²Œì‹œíŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {board_name}")
                
                try:
                    print(f"ê²Œì‹œíŒ '{board_name}' í´ë¦­ ì‹œë„ ì¤‘...")
                    
                    # ê²Œì‹œíŒìœ¼ë¡œ ì´ë™
                    if href and href.startswith('http'):
                        driver.get(href)
                        print(f"ê²Œì‹œíŒ '{board_name}' ë§í¬ë¡œ ì´ë™ ì„±ê³µ")
                    else:
                        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì „ì²´ URLë¡œ ë³€í™˜
                        full_url = f"https://cafe.naver.com{href}" if href.startswith('/') else href
                        driver.get(full_url)
                        print(f"ê²Œì‹œíŒ '{board_name}' ì „ì²´ URLë¡œ ì´ë™ ì„±ê³µ")
                    
                    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    
                    # í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥
                    try:
                        page_source = driver.page_source
                        with open("cafe_ì „ì²´ê¸€ë³´ê¸°_page_source.txt", "w", encoding="utf-8") as f:
                            f.write(page_source)
                        print("ì „ì²´ê¸€ë³´ê¸° í˜ì´ì§€ ì†ŒìŠ¤ê°€ 'cafe_ì „ì²´ê¸€ë³´ê¸°_page_source.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        print(f"ì „ì²´ê¸€ë³´ê¸° í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                    # ìµœê·¼ ê¸€ í¬ë¡¤ë§
                    total_recent_articles = scrape_recent_articles(driver, board_name)
                    
                    # ê³µêµ¬, í•«ë”œì´ í¬í•¨ëœ ê²Œì‹œíŒ í™•ì¸ (ê³µë°± ì œê±° í›„ ë¹„êµ)
                    special_keywords = ['ê³µêµ¬', 'í•«ë”œ']
                    special_boards = []
                    for board_name, href, link_element in unique_links:
                        board_name_no_space = board_name.replace(' ', '')
                        for keyword in special_keywords:
                            if keyword in board_name_no_space:
                                special_boards.append(board_name)
                                break
                    
                    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
                    print("\n" + "="*60)
                    print(f"ğŸ‰ ì „ì²´ê¸€ë³´ê¸° ìµœì¢… ê²°ê³¼: ìµœê·¼ 30ë¶„ ë‚´ ì´ {total_recent_articles}ê°œì˜ ê²Œì‹œê¸€ ë°œê²¬!")
                    
                    if special_boards:
                        print("ğŸ“¢ íŠ¹ë³„ ê²Œì‹œíŒ ë°œê²¬:")
                        for board in special_boards:
                            print(f"   â€¢ {board}")
                        print("ğŸ’¡ ìœ„ ê²Œì‹œíŒë“¤ì—ì„œë„ ìµœê·¼ ê¸€ì„ í™•ì¸í•´ë³´ì„¸ìš”!")
                    
                    print("="*60)
                    
                    return member_count, total_recent_articles, special_boards
                except Exception as e:
                    print(f"ê²Œì‹œíŒ '{board_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    try:
                        driver.switch_to.default_content()
                    except:
                        pass
                    return member_count, 0, []
            else:
                print("'ì „ì²´ê¸€ë³´ê¸°' ê²Œì‹œíŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ê²Œì‹œíŒ ëª©ë¡:")
                for i, (board_name, href, link_element) in enumerate(unique_links, 1):
                    print(f"{i}. {board_name}")
                return member_count, 0, []
        except Exception as e:
            print(f"ê²Œì‹œíŒ ì°¾ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("í˜„ì¬ í˜ì´ì§€ HTML êµ¬ì¡° í™•ì¸ ì¤‘...")
            try:
                page_source = driver.page_source
                print("í˜ì´ì§€ ì†ŒìŠ¤ ì¼ë¶€:", page_source[:1000])
            except:
                print("í˜ì´ì§€ ì†ŒìŠ¤ í™•ì¸ ì‹¤íŒ¨")
            return member_count, 0, []
    finally:
        driver.quit()

def get_processed_indices():
    """Eì—´(30ë¶„ ê²Œì‹œê¸€ ìˆ˜)ì— ê°’ì´ ìˆëŠ” í–‰ì˜ ì¸ë±ìŠ¤(0ë¶€í„° ì‹œì‘)ë¥¼ ë°˜í™˜"""
    creds = get_credentials()
    service = build('sheets', 'v4', credentials=creds)
    result = service.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range='ì¹´í˜_ë¦¬ìŠ¤íŠ¸!E2:E'  # Eì—´(í—¤ë” ì œì™¸)
    ).execute()
    values = result.get('values', [])
    processed_indices = []
    for i, row in enumerate(values):
        if row and row[0] and row[0].strip() != '':
            processed_indices.append(i)
    return processed_indices

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ë„¤ì´ë²„ ì¹´í˜ í¬ë¡¤ë§ ì‹œì‘!")
    print("êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì¹´í˜ URL ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    
    # êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì¹´í˜ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    cafe_urls = get_cafe_urls_from_sheet()
    processed_indices = get_processed_indices()
    
    if not cafe_urls:
        print("ì¹´í˜ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print(f"ì´ {len(cafe_urls)}ê°œì˜ ì¹´í˜ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    print(f"ì´ë¯¸ ì²˜ë¦¬ëœ ì¸ë±ìŠ¤: {processed_indices}")
    
    # ê° ì¹´í˜ë³„ë¡œ ì²˜ë¦¬ (ì´ë¯¸ ì²˜ë¦¬ëœ ì¸ë±ìŠ¤ëŠ” ê±´ë„ˆëœ€)
    for i, url in enumerate(cafe_urls):
        if i in processed_indices:
            print(f"[SKIP] {i+1}ë²ˆì§¸ ì¹´í˜ëŠ” ì´ë¯¸ ì²˜ë¦¬ë¨. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        try:
            print(f"\n{'='*80}")
            print(f"ì¹´í˜ {i+1}/{len(cafe_urls)} ì²˜ë¦¬ ì¤‘...")
            print(f"URL: {url}")
            print(f"{'='*80}")
            # ì¹´í˜ ë°ì´í„° ìŠ¤í¬ë˜í•‘
            member_count, recent_articles_count, hotdeal_boards = scrape_cafe_data(url, i)
            
            # êµ¬ê¸€ ì‹œíŠ¸ì— ê²°ê³¼ ì—…ë°ì´íŠ¸
            update_cafe_data(i, member_count, recent_articles_count, hotdeal_boards)
            
            print(f"ì¹´í˜ {i+1} ì²˜ë¦¬ ì™„ë£Œ!")
            
            # ë‹¤ìŒ ì¹´í˜ ì²˜ë¦¬ ì „ ì ì‹œ ëŒ€ê¸°
            if i < len(cafe_urls) - 1:
                print("ë‹¤ìŒ ì¹´í˜ ì²˜ë¦¬ ì „ 3ì´ˆ ëŒ€ê¸°...")
                time.sleep(3)
                
        except Exception as e:
            print(f"ì¹´í˜ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
    
    print(f"\n{'='*80}")
    print("ëª¨ë“  ì¹´í˜ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
